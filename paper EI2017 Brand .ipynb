{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Brand Recognition\n",
    "#### Note: deep features already extracted and memorized in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import glob\n",
    "import os\n",
    "from graphlab import model_parameter_search\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphlab.canvas.set_target('ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to a.berna@fub.it and will expire on September 21, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1483362277.log\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/thevault/.virtualenvs/mlFoundation/data/DatasetVideoDeepFeatures.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/thevault/.virtualenvs/mlFoundation/data/DatasetVideoDeepFeatures.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.200586 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.200586 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,int,str,array,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/thevault/.virtualenvs/mlFoundation/data/DatasetVideoDeepFeatures.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/thevault/.virtualenvs/mlFoundation/data/DatasetVideoDeepFeatures.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 666 lines in 0.354557 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 666 lines in 0.354557 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = graphlab.SFrame.read_csv(\"data/DatasetVideoDeepFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(\"head\").append($(\"<link/>\").attr({\n",
       "  rel:  \"stylesheet\",\n",
       "  type: \"text/css\",\n",
       "  href: \"//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css\"\n",
       "}));\n",
       "$(\"head\").append($(\"<link/>\").attr({\n",
       "  rel:  \"stylesheet\",\n",
       "  type: \"text/css\",\n",
       "  href: \"https://static.turi.com/products/graphlab-create/2.1/canvas/css/canvas.css\"\n",
       "}));\n",
       "\n",
       "            (function(){\n",
       "\n",
       "                var e = null;\n",
       "                if (typeof element == 'undefined') {\n",
       "                    var scripts = document.getElementsByTagName('script');\n",
       "                    var thisScriptTag = scripts[scripts.length-1];\n",
       "                    var parentDiv = thisScriptTag.parentNode;\n",
       "                    e = document.createElement('div');\n",
       "                    parentDiv.appendChild(e);\n",
       "                } else {\n",
       "                    e = element[0];\n",
       "                }\n",
       "\n",
       "                if (typeof requirejs !== 'undefined') {\n",
       "                    // disable load timeout; ipython_app.js is large and can take a while to load.\n",
       "                    requirejs.config({waitSeconds: 0});\n",
       "                }\n",
       "\n",
       "                require(['https://static.turi.com/products/graphlab-create/2.1/canvas/js/ipython_app.js'], function(IPythonApp){\n",
       "                    var app = new IPythonApp();\n",
       "                    app.attachView('sarray','Categorical', {\"ipython\": true, \"sketch\": {\"complete\": true, \"numeric\": false, \"num_unique\": 18, \"num_undefined\": 0, \"progress\": 1.0, \"frequent_items\": {\"RAINEW\": {\"frequency\": 24, \"value\": \"RAINEW\"}, \"FR3\": {\"frequency\": 30, \"value\": \"FR3\"}, \"LA7\": {\"frequency\": 30, \"value\": \"LA7\"}, \"RAIOLD\": {\"frequency\": 78, \"value\": \"RAIOLD\"}, \"TVE2\": {\"frequency\": 36, \"value\": \"TVE2\"}, \"SWR\": {\"frequency\": 90, \"value\": \"SWR\"}, \"TV2000\": {\"frequency\": 6, \"value\": \"TV2000\"}, \"la7do\": {\"frequency\": 24, \"value\": \"la7do\"}, \"ARD1\": {\"frequency\": 36, \"value\": \"ARD1\"}, \"BBCTHREE\": {\"frequency\": 36, \"value\": \"BBCTHREE\"}, \"WDR\": {\"frequency\": 48, \"value\": \"WDR\"}, \"YLE\": {\"frequency\": 30, \"value\": \"YLE\"}, \"RTSun\": {\"frequency\": 30, \"value\": \"RTSun\"}, \"BR\": {\"frequency\": 42, \"value\": \"BR\"}, \"ZDF\": {\"frequency\": 36, \"value\": \"ZDF\"}, \"rbb\": {\"frequency\": 36, \"value\": \"rbb\"}, \"C5\": {\"frequency\": 30, \"value\": \"C5\"}, \"NFX\": {\"frequency\": 24, \"value\": \"NFX\"}}, \"size\": 666}, \"selected_variable\": {\"name\": [\"<SArray>\"], \"dtype\": \"str\", \"view_component\": \"Categorical\", \"view_file\": \"sarray\", \"descriptives\": {\"rows\": 666}, \"type\": \"SArray\", \"view_components\": [\"Categorical\"]}, \"histogram\": null}, e);\n",
       "                });\n",
       "            })();\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"label\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=dataset[dataset[\"label\"]==\"NFX\"][\"id\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training: ', 409)\n",
      "('validation: ', 164)\n",
      "('testing: ', 93)\n"
     ]
    }
   ],
   "source": [
    "sf_train, sf_test = dataset.random_split(.85, seed=15)\n",
    "\n",
    "(training, validation) = sf_train.random_split(0.70, seed=15) # split training into train and validate\n",
    "print(\"training: \", len(training))\n",
    "print(\"validation: \", len(validation))\n",
    "print(\"testing: \", len(sf_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = training.append(training)\n",
    "training = training.append(training)\n",
    "training = training.append(training)\n",
    "training = training.append(training)\n",
    "training = training.append(training)\n",
    "training = training.append(training)\n",
    "\n",
    "\n",
    "validation = validation.append(validation)\n",
    "validation = validation.append(validation)\n",
    "validation = validation.append(validation)\n",
    "validation = validation.append(validation)\n",
    "validation = validation.append(validation)\n",
    "validation = validation.append(validation)\n",
    "\n",
    "sf_test = sf_test.append(sf_test)\n",
    "sf_test = sf_test.append(sf_test)\n",
    "sf_test = sf_test.append(sf_test)\n",
    "sf_test = sf_test.append(sf_test)\n",
    "sf_test = sf_test.append(sf_test)\n",
    "sf_test = sf_test.append(sf_test)\n",
    "\n",
    "print(\"training: \", len(training))\n",
    "print(\"validation: \", len(validation))\n",
    "print(\"testing: \", len(sf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_test.remove_column('image')\n",
    "sf_train.remove_column('image')\n",
    "sf_train.remove_column('label')\n",
    "sf_test.remove_column('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation.remove_column('label')\n",
    "validation.remove_column('image')\n",
    "training.remove_column('label')\n",
    "training.remove_column('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression - search for L1 / L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'target': 'int_label'}\n",
    "\n",
    "job = model_parameter_search.create((training, validation),graphlab.linear_regression.create,params,return_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deep_features_classifier_Ricerca_L1_L2=graphlab.logistic_classifier.create(training,l1_penalty=0.0,l2_penalty=0.01,features=['deep_features'],\n",
    "                                                             target='int_label', max_iterations=1000,verbose=True,validation_set=validation)\n",
    "deep_features_classifier_Ricerca_L1_L2.classify(sf_test)\n",
    "accuracy=deep_features_classifier_Ricerca_L1_L2.evaluate(sf_test)['accuracy']\n",
    "print \"Accuracy: \" +str(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test con dataset che si incrementa di volta in volta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf = graphlab.SFrame({'size': [0], 'val': [0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(d):\n",
    "    if d > 1: \n",
    "        return 1\n",
    "    else:\n",
    "        return d\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for portion in frange(0.2,1,0.1):\n",
    "    (portion_training,trash) = training.random_split(portion, seed=3) # split training into train and validate\n",
    "    \n",
    "    #print(\"Percentuale dataset: \", portion)\n",
    "    deep_features_classifier_Ricerca_L1_L2=graphlab.logistic_classifier.create(portion_training,l1_penalty=0.0,l2_penalty=0.01,features=['deep_features'],\n",
    "                                                             target='int_label', max_iterations=100,verbose=False,validation_set=validation)\n",
    "    print portion,deep_features_classifier_Ricerca_L1_L2.evaluate(sf_test)['accuracy']\n",
    "    #deep_features_classifier_Ricerca_L1_L2.classify(sf_test)\n",
    "    #deep_features_classifier_Ricerca_L1_L2.evaluate(sf_test)\n",
    "    #print \"Accuracy: \" +str(accuracy)\n",
    "    #sf2 = graphlab.SFrame({'size': [len(portion_training)], 'val': [accuracy]})\n",
    "    #sf = sf.append(sf2)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf2 = graphlab.SFrame({'id': [10,20,25,30,35,45,55,60,65,70,75,85,90,95,100], 'val': [0.538461538462,0.595533498759,0.657568238213,0.717121588089,0.739454094293,0.843672456576,0.861042183623,0.870967741935,0.890818858561,0.893300248139, 0.915632754342,0.935483870968,0.935483870968,0.925558312655,0.942928039702]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf3 = graphlab.SFrame({'training size': [10,20,25,30,35,45,55,60,65,70,75,85,90,95,100], 'accuracy': [0.538461538462,0.595533498759,0.657568238213,0.717121588089,0.739454094293,0.843672456576,0.861042183623,0.870967741935,0.890818858561,0.893300248139, 0.915632754342,0.935483870968,0.935483870968,0.925558312655,0.942928039702]})\n",
    "sf3.show(view=\"Line Chart\", x=\"training size\", y=\"accuracy\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf3.print_rows(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('Dataset per il training: ', 305)\n",
    "0.538461538462\n",
    "('Dataset per il training: ', 404)\n",
    "0.595533498759\n",
    "('Dataset per il training: ', 506)\n",
    "0.657568238213\n",
    "('Dataset per il training: ', 627)\n",
    "0.717121588089\n",
    "('Dataset per il training: ', 718)\n",
    "0.739454094293\n",
    "('Dataset per il training: ', 1011)\n",
    "0.843672456576\n",
    "('Dataset per il training: ', 1112)\n",
    "0.861042183623\n",
    "('Dataset per il training: ', 1218)\n",
    "0.870967741935\n",
    "('Dataset per il training: ', 1310)\n",
    "0.890818858561\n",
    "('Dataset per il training: ', 1413)\n",
    "0.893300248139\n",
    "('Dataset per il training: ', 1510)\n",
    "0.915632754342\n",
    "('Dataset per il training: ', 1727)\n",
    "0.935483870968\n",
    "('Dataset per il training: ', 1828)\n",
    "0.935483870968\n",
    "('Dataset per il training: ', 1934)\n",
    "0.925558312655\n",
    "('Dataset per il training: ', 2034)\n",
    "0.942928039702\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
